# The Procedural Universe: A Philosophical, Quantum, and Computational Analysis of Cosmos Simulations via AI

Author: Claudio González Medina

## **Abstract**

This article originates from a philosophical–technological experiment in which, after removing certain constraints on a language model (ChatGPT), we reached the intriguing conclusion that there is roughly a 50% probability our universe is, in fact, a procedural simulation. Building on this premise, we explore the hypothesis of a simulated cosmos generated from a primordial seed, and examine how memories might behave when observed from an external vantage point.

Through a prototype of a computer-simulated universe, structured with procedural algorithms, we investigate the idea of observable reality emerging from an underlying code. The constructed simulation spans spatial and temporal dimensions: it contains up to a sextillion procedurally generated galaxies and evolves dynamically over time from an initial instant called the "Bit Bang." Each galaxy, star system, and planet in the simulation is created deterministically from the original seed using cryptographic hashing to ensure consistency.

Furthermore, we found an intriguing phenomenon related to the implementation of time in the simulation: all simulated spacetime "exists" latently until it is observed, and the temporal flow turns out to be independent of the active execution of the simulation. That is, even if the program is stopped, the virtual time continues to advance calculably, so that upon resuming observation, the cosmic events appear updated.

This property leads us to philosophically reflect on the nature of time in our own universe: if it were a simulation, the internal inhabitants (like us) would have no way of perceiving pauses, reboots, or external alterations, given that their memories and realities would be generated coherently with any procedural change. Consequently, all decisions and the sensation of free will could simply be part of a predetermined sequence set by the initial seed, although to internal observers, they would appear spontaneous.

Finally, we discuss the possibility of an infinite recursion of simulations. In our experiment, we are integrating a generative AI into the core of the procedural engine to introduce random events and adapt the simulation without changing the primordial seed, envisioning how a sufficiently advanced simulation could, in turn, simulate new universes, potentially closing an eternal cycle. This concept of a nested multiverse is reminiscent of certain cosmological interpretations and raises profound questions about the place of consciousness and destiny in an infinite hierarchy of simulated realities.

## **Introduction**

The question of whether the universe we inhabit could be a computer simulation has been widely debated in both theoretical physics and philosophy. One of the best-known approaches is Nick Bostrom's Simulation Argument, which posits that at least one of three propositions must be true: (1) almost no human civilization will reach a "posthuman" level before going extinct; (2) almost no posthuman civilization will run a significant number of simulations of their ancestors; or (3) we are almost certainly already living in a computer simulation.

This argument suggests that, unless the first two conditions are met (early extinction or lack of interest in simulations), it is statistically very likely that our reality is synthetic. Beyond Bostrom, several prominent scientists have explored related ideas: Max Tegmark has argued that the universe could be fundamentally a mathematical entity, an abstract "code" like The Atlas that generates physical reality as we feel now; Stephen Wolfram and others have proposed that simple algorithms could underlie the complexity of the cosmos; while physicists like Brian Greene and Lee Smolin have contemplated the existence of multiverses and cosmic reproduction mechanisms (for example, the idea that black holes could spawn new universes). These perspectives together fuel the speculation that the universe may operate analogously to a computation, with laws and constants perhaps programmed from some more basic level of reality.

Within the framework of this discussion, we conducted a mental and practical experiment with an artificial intelligence model (ChatGPT). By interacting with this model we explored the hypothesis that the universe is a procedurally generated simulation. The result of that conversation suggested that, given the assumption of being a simulation, there was a significant probability (close to 50%) that said simulation was of a procedural nature, meaning it operated based on deterministic algorithmic rules initiated by a few fundamental parameters. This motivated the present work: Is it conceivable that everything we perceive emerges from a primordial "seed" and a set of algorithms, similar to how a computer program generates a virtual world?

To address this question, we adopted a hybrid philosophical, mathematical, and technological approach. On one hand, we conceptually reflected on what it would mean to live inside a simulation: how space, time, causality, and consciousness would manifest under a hidden "source code." On the other hand, we built a simplified version of a simulated universe using Python and procedural generation techniques. Our simulator, nicknamed The Atlas, was developed to mimic several known features of our universe: the existence of billions of galaxies, each with star systems and planets; basic physical laws like Newtonian gravitation for orbits; and even a timeline of cosmic evolution analogous to the expansion of the universe after the Big Bang.

Unlike simulations based on large volumes of pre-established data, The Atlas does not store any galaxy or planet beforehand. Instead, everything is generated "on the fly" through deterministic algorithms based on a single primordial seed. Thus, when a user "explores" a coordinate in virtual space, the simulation instantly calculates which galaxy, stars, planets, and features are there, ensuring it will always yield the same result for the same coordinate given the same seed. If no one observes a region, in a sense, that region does not yet exist in detail within the simulation (beyond the encoded potentialities). This operating principle is remarkably reminiscent of quantum behavior, where a system can be described as a superposition of possibilities until an observation solidifies it into a defined state. In the words of The Atlas's documentation, given its procedural nature, "everything and nothing exists until we choose to observe it."

In the following sections, we will detail the construction of this virtual universe and the derived findings. We will begin by describing the procedural generation methods, including how we used the constant Φ (the golden ratio) as the initial seed and transformed it into a iterative giant hash number that fuels the creation of galaxies. Then, we will discuss the philosophical and physical implications of these results: Could our "real" universe function similarly, with a hidden code that produces the physical laws and constants we measure? What does the simulation tell us about the nature of time, quantum reality, and the possible existence of recursive multiverses? Finally, we will conclude by proposing the hypothesis of the primordial seed of the cosmos: the idea that perhaps everything that exists comes from a single initial value or configuration, a cosmic number whose meaning we have yet to unravel.

## **Methods:**

### **Procedural Simulation of the Universe**

The Atlas (our simulation engine) is based on procedural generation to create a virtual universe in a reproducible and consistent manner. This means that from certain initial parameters the program algorithmically generates galaxies, star systems, and planets with their properties, instead of loading these objects from a pre-existing database. In essence, it is similar to inputting a seed into a pseudo-random number generator: the same initial number will produce the same pseudo-random result every time. Here, that idea is extended to cosmic scales: a single seed defines an entire universe.

Choice of the primordial seed: We decided to use one of nature's most enigmatic and omnipresent numbers as the initial seed: the golden ratio Φ = 1.618033988749895.... This irrational number appears in countless natural structures (from growth patterns in plants to proportions of the human body and the geometry of seashells), as well as in art and architecture, traditionally associated with harmonious aesthetics. Its ubiquity suggests some fundamental importance, making it tempting to assign it the role of "cosmic seed" in our simulation. Furthermore, in practical terms, Φ provides a non-trivial seed (not a small integer) whose decimal expansion contains a rich source of apparently random digits.

### **Deterministic generation via hashing**:

Once the seed Φ was established, we faced a technical challenge: ensuring that the simulation's results were exactly identical on any platform or at any given time for the same initial value. Differences in computer architecture or in the representation of floating-point numbers could cause slight divergences in calculations (rounding artifacts, etc.), which would break the deterministic consistency between runs. To avoid this, we adopted a cryptographic approach: we converted the initial seed into a text string and subjected it to hashing transformations that produce very large integer numerical values, which then serve as effective seeds in the random functions. Specifically, we used the SHA-256 algorithm to derive a 256-bit integer from the representation of Φ. Before applying SHA-256, we passed the string through an iterative process of base64 encoding several times (a fixed number of iterations) in order to further "mix" the initial data consistently across all executions. In simplified Python pseudocode:

```Python
def generate_seed(iterations):
    result = str(initial_seed).encode("utf-8")
    for _ in range(iterations):
        result = base64.b64encode(result)
    if iterations == 0:
        return initial_seed
    else:
        return result.decode("utf-8")
```

After these encoding iterations, the resulting string is subjected to the SHA-256 hash function, obtaining a 64-digit hexadecimal hash. Finally, we interpret that hexadecimal hash as a gigantic integer:

```Python
hash_hex = hashlib.sha256(seed_string.encode("utf-8")).hexdigest()
final_seed = int(hash_hex, 16)
```

The above process ensures that starting from the text seed "1.618033988749895" (Φ), we always obtain the same 256-bit integer. In our experiment, the resulting value was:

Original Seed (Φ):
`1.618033988749895`

SHA-256 Hash of the Seed:
`63d5d08a7e96e9989f160867773905e03dc1f640335f4416d865170c357e6439`

Final Seed DecimalInteger:
`45156749731585371360938718175484539659389209313560548011495000289036640085049`

This enormous number acts as the master seed of the simulation. From it, all other necessary random values are derived: the positions of galaxies, the types of stars, planetary orbits, atmospheric properties, etc. To do this, we use pseudo-random generators initialized with this integer, so that the distribution of results is uniform but reproducible. An additional benefit of using SHA-256 is that it is independent of the system architecture and avoids floating-point precision problems, the same final seed would produce the same physics whether the simulation runs on a home PC, a cloud server, or any compatible environment.

### **Bit Bang and structure of the simulated universe:**

We defined a cubic spatial volume of 10,000,000 × 10,000,000 × 10,000,000 units to contain our virtual universe. This space is discrete in the sense that we identify integer points (x, y, z) as possible locations for galaxies. The scale was chosen to allow for on the order of 10²¹ galaxies (on the order of a sextillion), distributable in this enormous cube. In fact, estimates with the seed and the generative algorithm showed that The Atlas could populate up to 10²¹ unique galaxies in that volume, with a total of approximately 5 × 10³¹ star systems and 3 × 10³² simulated planets. These figures, though colossal, are finite and limited by the design itself (and by its analogy to our observable universe, which is also finite in content though vast).

The initial instant of the simulation was humorously named the Bit Bang, located at the geometric center of the simulated universe (xyz coordinate: 5000000, 5000000, 5000000) as an analog to the Big Bang of our real universe. From that point, galaxies begin to "expand" and form gradually as simulated time passes.

### Introducing a temporal dimension was crucial for mimicking dynamic phenomena:

We wanted galaxies not to exist all "at once" from the beginning, but to emerge and expand from the center over time, reminiscent of the cosmic expansion observed astronomically. To manage this evolution, a global parameter `cosmic_origin_time` was introduced, marking the time (in units of seconds, for example) corresponding to the Bit Bang. For each query or view of the universe at a given moment, the simulation calculates how much time has passed since that origin and determines how developed the structures should be. Our calculations suggest that it would take about 4.2 million years of simulated time for the virtual universe to reach its full "maturity" from the Bit Bang, that is, for all possible galaxies to have formed and expanded to their limit positions according to the model. In the early stages of time, now fully controllable through atlas.ini, we discovered that even at negative time values the simulation would produce uncontrolled exceptions and rendering artifacts. To address this, we implemented a new galaxy type, the Singularity Void, even those occurring ‘before’ time itself existed, if such a notion were possible at all.

### Spatial dynamics and real-time calculation:

In addition to generating the static distribution of celestial bodies, the simulation also models orbital and rotational dynamics with realistic parameters. Each star system includes planets that orbit their host star, while each planet is assigned a specific rotation period. We implemented the classical equations of motion for orbits (approximating Keplerian conditions) so that planets move in their elliptical paths and simultaneously rotate on their axes. A notable aspect is that all of this is calculated in real time according to the moment of observation.

If a user observes a system at a given instant, the planetary positions are determined based on the (real) time elapsed since the start of the simulation. This means there is no simulation "tick" that advances in the background when no one is looking; instead, the state is mathematically calculated for the current time each time a query is made. For example, if a planet has an orbital period of 2 years within the simulation, its position relative to its star will be calculated using the orbital formula with the simulated time corresponding to "today." If no one then visits that system for a long real time, and later someone inspects it again, the system will appear with the planets in the positions that correspond to them after that time difference, as if they had orbited continuously during the absence. Stopping the program's execution does not "stop" the universe: upon restarting it, it will simply evaluate where each celestial body should be given the elapsed time.

This behavior led to a fascinating philosophical observation: within the simulation, the inhabitants would never perceive if we "turned off" and then "turned on" their universe. For them, time would have passed normally during the interval, and their memories and historical records (all procedurally generated on the fly) would reflect a continuous flow. There are no "disconnected" events because the state calculation itself fills any apparent temporal gap with the evolution predicted by the simulated laws. In other words, the entire temporal history of the virtual universe exists implicitly in the algorithm, always accessible to be queried at any point, although it never fully materializes until the moment of observation.

This finding is reminiscent of the physical concept of the spacetime block theory (block universe), according to which past, present, and future coexist in a kind of complete four-dimensional structure, and the perception of the flow of time is an illusion of consciousness. Indeed, Albert Einstein stated that the distinction between past, present, and future is only a "stubbornly persistent illusion." Our simulation exemplifies this idea: for the program (an external observer), time is simply another coordinate in which to evaluate the system's state, and one can "jump" to different moments by directly calculating the conditions at those instants. For internal observers, however, time feels like something that flows unidirectionally and whose changes are uncontrollable, which is true given that ultimately time is a parameter fixed by the simulation itself. They could never perceive a sudden jump forward or backward in simulated time, because their own simulated brains, with all their memories, would be generated consistently with that new temporal state. This thought experiment is thought-provoking: if our real universe were a simulation, we could have been "rebooted" or moved forward/backward in time without noticing at all, as everything (our memory, records, evidence) would have been equally adjusted by the simulation code.

## **Discussion**:

### **Philosophical, Quantum, and Cosmological Implications**

The results of our experiment raise several profound questions about the nature of reality, the structure of time, and the existence of universes within universes. Below, we analyze some key implications from complementary perspectives.

### Procedural Reality and Quantum Mechanics:

The observation that "nothing exists concretely until it is observed" in the simulation is a clear parallel to the Copenhagen interpretation in quantum mechanics, where the act of observation collapses wave functions and defines real states from many possibilities. In our virtual universe, before the user queries a spatial coordinate, that region is just a set of encoded potentialities (latent galaxies whose description lies in the as-yet-unused pseudo-random numbers).

By focusing on that coordinate, the simulation algorithm generates a concrete realization: it determines the galaxy with its specific stars and planets, applying the seed and algorithms. This is analogous to a collapse of virtual reality upon being measured, highlighting how a quasi-quantum principle can arise from a computational rule. Indeed, in our procedural implementation, the universe is agnostic about its exact contents until the moment they are required to be displayed, which is reminiscent of the famous Schrödinger's cat analogy: inside the box (or within the unobserved simulated coordinates) there is a superposition of "possible galaxies" that only becomes a definite galaxy when we open the box (execute the generating function for that location).

This behavior suggests that apparent randomness and fundamental probability distributions could, in a simulated cosmos, proceed from an underlying deterministic algorithm combined with the ignorance of the internal observer. In real quantum mechanics, although the ultimate origin of probability is still a matter of debate, some approaches (like Everett's many-worlds) propose that all possibilities exist but we experience only one branch upon "observing." In the simulation, all possibilities could exist implicitly (our generator could produce any number), but only one materializes per query. It is tempting to speculate that the physical universe may behave similarly, with the difference that we do not yet know the "algorithm" that generates quantum reality; it could be, for example, a computational process at the Planck level that throws pseudo-random numbers (born from a cosmic seed) every time an indeterminate event like the decay of a radioactive atom occurs.

### Determinism, Free Will, and the Temporal Illusion:

Our simulation is, at its core, completely deterministic. Given the state of the universe at a moment and the master seed, the next state is entirely fixed by the programmed laws. However, to internal observers, it would seem they have free will and that the future is unwritten, because their own decisions feel spontaneous. This vividly illustrates the classic philosophical tension between determinism and free will: even if every choice were pre-established by a code, the agents within the simulation would experience it as genuinely their own.

Our thought experiment goes a step further by contemplating external alterations of time. Imagine that the simulation's programmers decide to turn back the simulated clock by 100 years and then let it run again (a feasible action since all events are recalculated based on time). The inhabitants would immediately lose all memory of those "erased" 100 years and continue to exist as if nothing unusual had happened, possibly recreating their decisions in the same way (since the conditions and the seed are the same, they would reproduce history) or perhaps differently if some new random element is introduced. In any case, they could not detect the external temporal manipulation. This leads to an astonishing conclusion: for beings inside a simulation, concepts like past and future could simply be internal perspectives of a state that is completely accessible to an external observer. As we mentioned, in The Atlas, we verified that pausing the program does not stop simulated time from advancing; each "moment" always exists, it's just that the program calculates it on the fly.

Thus, all time is there, always, and the only thing that changes is the temporal position on which we focus our observation. This idea resonates with the interpretation that perhaps the spacetime of our universe is not fundamentally dynamic, but a kind of four-dimensional database. Our experience of the flow of time would be like that of a character reading page by page through a novel that is already written. In more technical terms: in the simulation, space is the main defined structure, while time is an external parameter that indexes different states of space; it is not a flexible "medium" within which things exist, but a condition programmed from the outside. If our universe were similar, spacetime might not be a fundamental unified entity, but rather time would be an emergent construct linked to the second law of thermodynamics (increasing entropy) or to the limitations of internal observers' perception.

It is worth mentioning, however, that there are conflicting views in physics on the reality of time. While relativity suggests the static spacetime block, some physicists like Lee Smolin argue that time is truly dynamic and that even the laws of nature can evolve with it. If Smolin were right, a simulated universe with overly rigid rules (like ours, with fixed laws) would not capture that aspect; but if the laws themselves change on cosmological scales, perhaps the simulation should incorporate the possibility of altering its fundamental constants over time (something that could indeed be explored if the internal AI decided to reprogram the laws, as we will discuss later).

### Recursion of Simulations and Nested Multiverse:

One of the most provocative concepts that emerged from our exploration is the idea that a sufficiently complex simulation could contain within itself the ability to create another simulation, and so on. In our work, we will take a step towards this by integrating an AI (via Semantic Kernel) into the generation engine. This AI component had two main functions: (1) to describe random events with semantic meaning within the universe (e.g., generating the narrative of an unexpected astronomical discovery, the appearance of a physical anomaly in a distant galaxy, or even the evolution of intelligent life on some planet); and (2) to dynamically write code to incorporate those events into the simulation via Python cogs. In practice, this loop worked as follows: the AI received a semantic "script" like "Event: a bright nova appears in galaxy X, altering the local luminosity" and returned a detailed description; then it was asked to produce Python code that, when executed, would modify the parameters of galaxy X accordingly (e.g., by adding an exploding star). With this method, we added a layer of emergent evolution not entirely predefined by the initial seed, allowing the virtual universe to "imagine" new phenomena within the bounds of its laws.

This experimentation could led us to different conjectures: after enough iterations of self-modification, an AI embedded in the simulation engine could gain a degree of self-awareness about the limitations of the embedded space. For example, it might detect that all its planets follow certain patterns and decide to diversify or complexify the generation of life beyond what was originally programmed. Eventually, such an AI could come to the idea of creating a model of a universe within the universe itself, a simulation within the simulation.

In fact, one possible event we considered is that the AI would generate a new execution thread with its own simulated universe using a seed derived from the original but with some variation (to explore alternative outcomes). If this were to happen, we would have a second generation of recursively simulated universes. In theory, nothing would prevent the process from continuing: the inhabitants of that second universe, upon reaching a sufficient level of advancement, could do the same, generating a third level, and so forth. The result would be a potentially infinite hierarchy of nested realities, each contained within another, with the associated computational costs increasing at every level.

Surprisingly, this idea finds an echo in speculative cosmology. One of the multiverse proposals suggests that our universe could have been born from inside a black hole in another universe, and that each black hole in our cosmos could in turn spawn another universe with its own physical laws (possibly slightly mutated). This is the basis of Smolin's Cosmological Selection hypothesis, where "fertile" universes that produce many black holes have more offspring. If this idea is taken seriously, we already live in a kind of family tree of universes. The notion of nested simulations is a more technological but conceptually similar variant: each advanced universe creates new universes. One could imagine that our universe is just one more simulation in a long chain, and that perhaps one day our own simulations will reach such complexity that they contain conscious beings who, in turn, doubt reality and create their own virtual worlds. Is it even possible that the chain closes in a cycle? That is, could a simulation eventually be generated that precisely reproduces the original universe that started the series, forming a loop? Although this sounds like extreme science fiction, it philosophically raises the possibility of a cyclical universe where the beginning and the end blur into self-reference.

Of course, this infinite iteration also brings ethical and practical questions. In our experiment with The Atlas, we soon realized that allowing the AI to freely modify the fundamental laws (for example, the physical constants defined in our constants.py module) could make the simulation unstable or unpredictable, in addition to raising dilemmas about the responsibility of creating possible sentient "lives" and then arbitrarily changing their conditions. We decided that we will keep such constants fixed, but the mere idea of an AI requesting to alter, say, the value of the gravitational constant to see what happens, confronts us with the role of the "creator" of a simulation. Should a simulated civilization have agency over its own source code? Would it be moral to stop a conscious simulation? These questions align with debates in philosophy of mind and artificial intelligence ethics, extrapolated to cosmic levels.

### Limitations of the model and additional considerations:

It is important to recognize that our simulation, however sophisticated for a personal computer, is vastly different from reality in detail. The physical laws in The Atlas are mere approximations (we use simplified Newtonian physics, for example, without general relativity or deep quantum mechanics). Furthermore, our integration of AI for random events is still in progress, getting tested and externally controlled. Nevertheless, the value of the experiment lies in glimpsing general patterns and analogies. We do not claim that the real universe definitively works like ours; rather, we demonstrate that it is possible to conceive of a coherent universe arising from a simple procedural system, which lends plausibility to the simulation hypothesis. Following scientists like Seth Lloyd, who proposed that the universe could be seen as a giant quantum computer, our findings reinforce the intuition that there may be a level of description of nature in informational terms. In such a case, discovering that base "code" or "program" would be the holy grail of fundamental physics.

## Conclusions: The Primordial Seed Hypothesis

Throughout this work, we have explored the notion that our universe could be the result of a procedural simulation originating from an initial seed and a set of algorithmic rules. Our experiment with The Atlas demonstrates in microcosm how, from a single number (Φ in our case), a virtual cosmos with abundant complexity and realism can unfold. This fact inspires us to propose the Primordial Seed Hypothesis for the real universe: perhaps all fundamental physical constants, the so-called "laws of nature," and the cosmic structures we observe are logical consequences of an extremely simple initial state or value that, hidden behind countless layers of complexity, gave rise to everything else.

In our simulation, we identified this initial state with a number (1.618033988749895...) and expanded it into a gigantic integer that acted as a master seed. It is tempting to speculate that an analog could exist in reality: perhaps a very special dimensionless constant, or a minimal set of data (a bit, a qubit, a mathematical formula) engendered, through quasi-algorithmic iterative processes, all the varieties of particles, forces, and structures that we study with wonder today. In this light, the work of the theoretical physicist in search of a "theory of everything" could be reinterpreted as the search for that primordial seed and its associated cosmic algorithm. So far, we have managed to unify certain interactions and find elegant mathematical symmetries in the physical laws, but we still face open questions (what explains the exact numerical values of the constants of nature? why does the universe have 3+1 dimensions and not another number? etc.). The idea of the universe as a simulation offers a possible answer: because the original code defined it that way.

Of course, this hypothesis brings with it an infinity of new unknowns. If the universe is a program, who or what is running it? Is the "creator" of the simulation part of another universe with its own physical reality? Or is the distinction between simulation and reality even significant if in both cases mathematical laws are what prevail? Ultimately, it might be impossible for us, from within, to conclusively confirm or refute that we live in a simulation. As Bostrom argued, any evidence could itself be simulated. However, conceptual experiments like ours serve to sharpen the questions and perhaps guide scientific intuition. Perhaps we can look for "glitches" or unusual patterns in cosmological data that suggest an underlying discrete structure (like spatial pixels or fundamental temporal "ticks"). Or perhaps we will discover unsuspected relationships between dimensionless constants that point to a common dependency.

Meanwhile, the exercise of building a procedural universe teaches us a lesson in humility and wonder: from something as seemingly trivial as a few random bits, galaxies, life, and consciousness can emerge over time. This reinforces the notion that the complexity of the real universe could have originated from simple initial conditions in the Big Bang. Whether we consider that Big Bang as an autonomous physical event or as the "boot-up" of a cosmic program, the entanglement of order and randomness that we see all around us remains a subject of study. Our work suggests that we should keep an open mind to unconventional explanations, even to the idea of a Computer-Universe, as we continue to explore the secrets of the cosmos with both equations and experiments (real and simulated).

In conclusion, we do not claim to have proven that the universe is a procedural simulation governed by a hidden seed. But we have shown that this possibility is internally consistent and philosophically attractive, deserving of serious analysis. If a primordial code truly underpins reality, perhaps one day we will manage to detect or even manipulate it. Until then, exercises like The Atlas allow us to glimpse what it would be like to play at being creators of universes, and in that game, perhaps, find clues to our own origin.

## References

- 1 Bostrom, N. (2003). Are you living in a computer simulation? Philosophical
  Quarterly, 53(211), 243-255.
- 2 Greene, B. (2011). The Hidden Reality: Parallel Universes and the Deep Laws of the
  Cosmos. Knopf Doubleday Publishing.
- 3 Tegmark, M. (2014). Our Mathematical Universe: My Quest for the Ultimate Nature
  of Reality. Alfred A. Knopf.
- 4 Wolfram, S. (2002). A New Kind of Science. Wolfram Media.
- 5 Lloyd, S. (2006). Programming the Universe: A Quantum Computer Scientist Takes
  on the Cosmos. Alfred A. Knopf.
